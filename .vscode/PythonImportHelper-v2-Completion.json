[
    {
        "label": "requests",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "requests",
        "description": "requests",
        "detail": "requests",
        "documentation": {}
    },
    {
        "label": "load_dataset",
        "importPath": "datasets",
        "description": "datasets",
        "isExtraImport": true,
        "detail": "datasets",
        "documentation": {}
    },
    {
        "label": "load_dataset",
        "importPath": "datasets",
        "description": "datasets",
        "isExtraImport": true,
        "detail": "datasets",
        "documentation": {}
    },
    {
        "label": "BeautifulSoup",
        "importPath": "bs4",
        "description": "bs4",
        "isExtraImport": true,
        "detail": "bs4",
        "documentation": {}
    },
    {
        "label": "BeautifulSoup",
        "importPath": "bs4",
        "description": "bs4",
        "isExtraImport": true,
        "detail": "bs4",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "KaggleApi",
        "importPath": "kaggle.api.kaggle_api_extended",
        "description": "kaggle.api.kaggle_api_extended",
        "isExtraImport": true,
        "detail": "kaggle.api.kaggle_api_extended",
        "documentation": {}
    },
    {
        "label": "ast",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "ast",
        "description": "ast",
        "detail": "ast",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "SequenceMatcher",
        "importPath": "difflib",
        "description": "difflib",
        "isExtraImport": true,
        "detail": "difflib",
        "documentation": {}
    },
    {
        "label": "SequenceMatcher",
        "importPath": "difflib",
        "description": "difflib",
        "isExtraImport": true,
        "detail": "difflib",
        "documentation": {}
    },
    {
        "label": "Flask",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "request",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "jsonify",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "Flask",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "render_template",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "request",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "send_file",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "Api",
        "importPath": "flask_restful",
        "description": "flask_restful",
        "isExtraImport": true,
        "detail": "flask_restful",
        "documentation": {}
    },
    {
        "label": "Resource",
        "importPath": "flask_restful",
        "description": "flask_restful",
        "isExtraImport": true,
        "detail": "flask_restful",
        "documentation": {}
    },
    {
        "label": "detect_plagiarism",
        "importPath": "plagiarism_detector",
        "description": "plagiarism_detector",
        "isExtraImport": true,
        "detail": "plagiarism_detector",
        "documentation": {}
    },
    {
        "label": "detect_plagiarism",
        "importPath": "plagiarism_detector",
        "description": "plagiarism_detector",
        "isExtraImport": true,
        "detail": "plagiarism_detector",
        "documentation": {}
    },
    {
        "label": "load_code",
        "importPath": "plagiarism_detector",
        "description": "plagiarism_detector",
        "isExtraImport": true,
        "detail": "plagiarism_detector",
        "documentation": {}
    },
    {
        "label": "preprocess_code",
        "importPath": "plagiarism_detector",
        "description": "plagiarism_detector",
        "isExtraImport": true,
        "detail": "plagiarism_detector",
        "documentation": {}
    },
    {
        "label": "tokenize_code",
        "importPath": "plagiarism_detector",
        "description": "plagiarism_detector",
        "isExtraImport": true,
        "detail": "plagiarism_detector",
        "documentation": {}
    },
    {
        "label": "normalize_code",
        "importPath": "plagiarism_detector",
        "description": "plagiarism_detector",
        "isExtraImport": true,
        "detail": "plagiarism_detector",
        "documentation": {}
    },
    {
        "label": "compute_ast",
        "importPath": "plagiarism_detector",
        "description": "plagiarism_detector",
        "isExtraImport": true,
        "detail": "plagiarism_detector",
        "documentation": {}
    },
    {
        "label": "compute_cfg",
        "importPath": "plagiarism_detector",
        "description": "plagiarism_detector",
        "isExtraImport": true,
        "detail": "plagiarism_detector",
        "documentation": {}
    },
    {
        "label": "compute_hash_similarity",
        "importPath": "plagiarism_detector",
        "description": "plagiarism_detector",
        "isExtraImport": true,
        "detail": "plagiarism_detector",
        "documentation": {}
    },
    {
        "label": "compute_structural_similarity",
        "importPath": "plagiarism_detector",
        "description": "plagiarism_detector",
        "isExtraImport": true,
        "detail": "plagiarism_detector",
        "documentation": {}
    },
    {
        "label": "compute_synthetic_similarity",
        "importPath": "plagiarism_detector",
        "description": "plagiarism_detector",
        "isExtraImport": true,
        "detail": "plagiarism_detector",
        "documentation": {}
    },
    {
        "label": "compute_behavioral_similarity",
        "importPath": "plagiarism_detector",
        "description": "plagiarism_detector",
        "isExtraImport": true,
        "detail": "plagiarism_detector",
        "documentation": {}
    },
    {
        "label": "detect_plagiarism",
        "importPath": "plagiarism_detector",
        "description": "plagiarism_detector",
        "isExtraImport": true,
        "detail": "plagiarism_detector",
        "documentation": {}
    },
    {
        "label": "BytesIO",
        "importPath": "io",
        "description": "io",
        "isExtraImport": true,
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "BytesIO",
        "importPath": "io",
        "description": "io",
        "isExtraImport": true,
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "matplotlib.pyplot",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.pyplot",
        "description": "matplotlib.pyplot",
        "detail": "matplotlib.pyplot",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "csv",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "csv",
        "description": "csv",
        "detail": "csv",
        "documentation": {}
    },
    {
        "label": "compare_codes",
        "importPath": "compare",
        "description": "compare",
        "isExtraImport": true,
        "detail": "compare",
        "documentation": {}
    },
    {
        "label": "compare_codes",
        "importPath": "compare",
        "description": "compare",
        "isExtraImport": true,
        "detail": "compare",
        "documentation": {}
    },
    {
        "label": "extract_similarity_features",
        "importPath": "compare",
        "description": "compare",
        "isExtraImport": true,
        "detail": "compare",
        "documentation": {}
    },
    {
        "label": "generate_pdf_report",
        "importPath": "generate_report",
        "description": "generate_report",
        "isExtraImport": true,
        "detail": "generate_report",
        "documentation": {}
    },
    {
        "label": "fetch_github_code",
        "importPath": "fetchers.github_fetch",
        "description": "fetchers.github_fetch",
        "isExtraImport": true,
        "detail": "fetchers.github_fetch",
        "documentation": {}
    },
    {
        "label": "fetch_github_code",
        "importPath": "fetchers.github_fetch",
        "description": "fetchers.github_fetch",
        "isExtraImport": true,
        "detail": "fetchers.github_fetch",
        "documentation": {}
    },
    {
        "label": "FlaskForm",
        "importPath": "flask_wtf",
        "description": "flask_wtf",
        "isExtraImport": true,
        "detail": "flask_wtf",
        "documentation": {}
    },
    {
        "label": "Form",
        "importPath": "wtforms",
        "description": "wtforms",
        "isExtraImport": true,
        "detail": "wtforms",
        "documentation": {}
    },
    {
        "label": "SelectField",
        "importPath": "wtforms",
        "description": "wtforms",
        "isExtraImport": true,
        "detail": "wtforms",
        "documentation": {}
    },
    {
        "label": "DataRequired",
        "importPath": "wtforms.validators",
        "description": "wtforms.validators",
        "isExtraImport": true,
        "detail": "wtforms.validators",
        "documentation": {}
    },
    {
        "label": "canvas",
        "importPath": "reportlab.pdfgen",
        "description": "reportlab.pdfgen",
        "isExtraImport": true,
        "detail": "reportlab.pdfgen",
        "documentation": {}
    },
    {
        "label": "A4",
        "importPath": "reportlab.lib.pagesizes",
        "description": "reportlab.lib.pagesizes",
        "isExtraImport": true,
        "detail": "reportlab.lib.pagesizes",
        "documentation": {}
    },
    {
        "label": "networkx",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "networkx",
        "description": "networkx",
        "detail": "networkx",
        "documentation": {}
    },
    {
        "label": "preprocess_code",
        "importPath": "preprocess",
        "description": "preprocess",
        "isExtraImport": true,
        "detail": "preprocess",
        "documentation": {}
    },
    {
        "label": "get_ast_structure",
        "importPath": "language_parsers.ast_parser",
        "description": "language_parsers.ast_parser",
        "isExtraImport": true,
        "detail": "language_parsers.ast_parser",
        "documentation": {}
    },
    {
        "label": "tokenize_code",
        "importPath": "tokenizer",
        "description": "tokenizer",
        "isExtraImport": true,
        "detail": "tokenizer",
        "documentation": {}
    },
    {
        "label": "normalize_code",
        "importPath": "normalize",
        "description": "normalize",
        "isExtraImport": true,
        "detail": "normalize",
        "documentation": {}
    },
    {
        "label": "hash_code",
        "importPath": "hash_similarity",
        "description": "hash_similarity",
        "isExtraImport": true,
        "detail": "hash_similarity",
        "documentation": {}
    },
    {
        "label": "generate_cfg",
        "importPath": "cfg_generator",
        "description": "cfg_generator",
        "isExtraImport": true,
        "detail": "cfg_generator",
        "documentation": {}
    },
    {
        "label": "accuracy_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "precision_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "recall_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "f1_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "confusion_matrix",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "roc_curve",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "auc",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "accuracy_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "precision_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "recall_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "f1_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "confusion_matrix",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "fetch_reference_codes",
        "importPath": "fetchers.codesearchnet_fetch",
        "description": "fetchers.codesearchnet_fetch",
        "isExtraImport": true,
        "detail": "fetchers.codesearchnet_fetch",
        "documentation": {}
    },
    {
        "label": "fetch_reference_codes",
        "importPath": "fetchers.codesearchnet_fetch",
        "description": "fetchers.codesearchnet_fetch",
        "isExtraImport": true,
        "detail": "fetchers.codesearchnet_fetch",
        "documentation": {}
    },
    {
        "label": "OpenAI",
        "importPath": "openai",
        "description": "openai",
        "isExtraImport": true,
        "detail": "openai",
        "documentation": {}
    },
    {
        "label": "matplotlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib",
        "description": "matplotlib",
        "detail": "matplotlib",
        "documentation": {}
    },
    {
        "label": "FPDF",
        "importPath": "fpdf",
        "description": "fpdf",
        "isExtraImport": true,
        "detail": "fpdf",
        "documentation": {}
    },
    {
        "label": "hashlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "hashlib",
        "description": "hashlib",
        "detail": "hashlib",
        "documentation": {}
    },
    {
        "label": "argparse",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "argparse",
        "description": "argparse",
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "fetch_gfg_code",
        "importPath": "fetchers.gfg_fetch",
        "description": "fetchers.gfg_fetch",
        "isExtraImport": true,
        "detail": "fetchers.gfg_fetch",
        "documentation": {}
    },
    {
        "label": "fetch_cf_info",
        "importPath": "fetchers.codeforces_fetch",
        "description": "fetchers.codeforces_fetch",
        "isExtraImport": true,
        "detail": "fetchers.codeforces_fetch",
        "documentation": {}
    },
    {
        "label": "joblib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "joblib",
        "description": "joblib",
        "detail": "joblib",
        "documentation": {}
    },
    {
        "label": "ast_parser",
        "importPath": "language_parsers",
        "description": "language_parsers",
        "isExtraImport": true,
        "detail": "language_parsers",
        "documentation": {}
    },
    {
        "label": "cpp_parser",
        "importPath": "language_parsers",
        "description": "language_parsers",
        "isExtraImport": true,
        "detail": "language_parsers",
        "documentation": {}
    },
    {
        "label": "java_parser",
        "importPath": "language_parsers",
        "description": "language_parsers",
        "isExtraImport": true,
        "detail": "language_parsers",
        "documentation": {}
    },
    {
        "label": "nltk",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "nltk",
        "description": "nltk",
        "detail": "nltk",
        "documentation": {}
    },
    {
        "label": "word_tokenize",
        "importPath": "nltk.tokenize",
        "description": "nltk.tokenize",
        "isExtraImport": true,
        "detail": "nltk.tokenize",
        "documentation": {}
    },
    {
        "label": "RandomForestClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "train_test_split",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "fetch_cf_info",
        "kind": 2,
        "importPath": "fetchers.codeforces_fetch",
        "description": "fetchers.codeforces_fetch",
        "peekOfCode": "def fetch_cf_info(username):\n    url = f\"https://codeforces.com/api/user.info?handles={username}\"\n    res = requests.get(url).json()\n    if res[\"status\"] != \"OK\":\n        print(\"‚ùå Codeforces user not found!\")\n        return\n    user = res[\"result\"][0]\n    print(f\"üéñÔ∏è Handle: {user['handle']}\")\n    print(f\"üèÖ Rating: {user.get('rating', 'Unrated')}\")\n    print(f\"üìà Max Rating: {user.get('maxRating', 'N/A')}\")",
        "detail": "fetchers.codeforces_fetch",
        "documentation": {}
    },
    {
        "label": "fetch_reference_codes",
        "kind": 2,
        "importPath": "fetchers.codesearchnet_fetch",
        "description": "fetchers.codesearchnet_fetch",
        "peekOfCode": "def fetch_reference_codes(language: str, max_files: int = 10):\n    \"\"\"\n    Fetches top `max_files` code snippets for `language` from CodeSearchNet\n    and writes them to reference_codes/{language}_{i}.<ext>\n    \"\"\"\n    ds = load_dataset(\n        \"code_search_net\", \n        language, \n        split=\"train\", \n        trust_remote_code=True",
        "detail": "fetchers.codesearchnet_fetch",
        "documentation": {}
    },
    {
        "label": "fetch_gfg_code",
        "kind": 2,
        "importPath": "fetchers.gfg_fetch",
        "description": "fetchers.gfg_fetch",
        "peekOfCode": "def fetch_gfg_code(username):\n    url = f\"https://auth.geeksforgeeks.org/user/{username}/practice/\"\n    res = requests.get(url)\n    if res.status_code != 200:\n        print(\"‚ùå GFG user not found!\")\n        return\n    soup = BeautifulSoup(res.text, 'html.parser')\n    titles = soup.find_all('span', class_='score_card_problem_name')\n    print(f\"‚úÖ {len(titles)} problems fetched for {username}\")\n    for t in titles[:5]:",
        "detail": "fetchers.gfg_fetch",
        "documentation": {}
    },
    {
        "label": "download_code_files",
        "kind": 2,
        "importPath": "fetchers.github_fetch",
        "description": "fetchers.github_fetch",
        "peekOfCode": "def download_code_files(repo_full_name, lang, ext, max_files=3):\n    url = f\"https://api.github.com/repos/{repo_full_name}/contents\"\n    r = requests.get(url, headers=HEADERS)\n    if r.status_code != 200:\n        print(f\"  ‚ö†Ô∏è Couldn't list {repo_full_name}: HTTP {r.status_code}\")\n        return\n    files = r.json()\n    saved = 0\n    save_dir = os.path.join(\"reference_codes\", lang)\n    os.makedirs(save_dir, exist_ok=True)",
        "detail": "fetchers.github_fetch",
        "documentation": {}
    },
    {
        "label": "fetch_github_code",
        "kind": 2,
        "importPath": "fetchers.github_fetch",
        "description": "fetchers.github_fetch",
        "peekOfCode": "def fetch_github_code():\n    for lang, ext in LANGUAGES.items():\n        print(f\"\\nüîç Fetching top repos for {lang}\")\n        r = requests.get(SEARCH_URL.format(lang), headers=HEADERS)\n        if r.status_code != 200:\n            print(f\"‚ùå Search failed for {lang}: HTTP {r.status_code}\")\n            continue\n        for repo in r.json().get(\"items\", []):\n            print(\"üì¶\", repo[\"full_name\"])\n            download_code_files(repo[\"full_name\"], lang, ext)",
        "detail": "fetchers.github_fetch",
        "documentation": {}
    },
    {
        "label": "GITHUB_TOKEN",
        "kind": 5,
        "importPath": "fetchers.github_fetch",
        "description": "fetchers.github_fetch",
        "peekOfCode": "GITHUB_TOKEN = os.getenv(\"GITHUB_TOKEN\")\nif not GITHUB_TOKEN:\n    print(\"‚ùå Please create a .env file with GITHUB_TOKEN=<your‚Äëtoken>\")\n    exit(1)\nLANGUAGES = {\n    \"python\": \".py\",\n    \"java\":   \".java\",\n    \"cpp\":    \".cpp\",\n}\nSEARCH_URL = \"https://api.github.com/search/repositories?q=language:{}&sort=stars&per_page=5\"",
        "detail": "fetchers.github_fetch",
        "documentation": {}
    },
    {
        "label": "LANGUAGES",
        "kind": 5,
        "importPath": "fetchers.github_fetch",
        "description": "fetchers.github_fetch",
        "peekOfCode": "LANGUAGES = {\n    \"python\": \".py\",\n    \"java\":   \".java\",\n    \"cpp\":    \".cpp\",\n}\nSEARCH_URL = \"https://api.github.com/search/repositories?q=language:{}&sort=stars&per_page=5\"\nHEADERS = {\n    \"Authorization\": f\"token {GITHUB_TOKEN}\",\n    \"Accept\":        \"application/vnd.github.v3+json\"\n}",
        "detail": "fetchers.github_fetch",
        "documentation": {}
    },
    {
        "label": "SEARCH_URL",
        "kind": 5,
        "importPath": "fetchers.github_fetch",
        "description": "fetchers.github_fetch",
        "peekOfCode": "SEARCH_URL = \"https://api.github.com/search/repositories?q=language:{}&sort=stars&per_page=5\"\nHEADERS = {\n    \"Authorization\": f\"token {GITHUB_TOKEN}\",\n    \"Accept\":        \"application/vnd.github.v3+json\"\n}\ndef download_code_files(repo_full_name, lang, ext, max_files=3):\n    url = f\"https://api.github.com/repos/{repo_full_name}/contents\"\n    r = requests.get(url, headers=HEADERS)\n    if r.status_code != 200:\n        print(f\"  ‚ö†Ô∏è Couldn't list {repo_full_name}: HTTP {r.status_code}\")",
        "detail": "fetchers.github_fetch",
        "documentation": {}
    },
    {
        "label": "HEADERS",
        "kind": 5,
        "importPath": "fetchers.github_fetch",
        "description": "fetchers.github_fetch",
        "peekOfCode": "HEADERS = {\n    \"Authorization\": f\"token {GITHUB_TOKEN}\",\n    \"Accept\":        \"application/vnd.github.v3+json\"\n}\ndef download_code_files(repo_full_name, lang, ext, max_files=3):\n    url = f\"https://api.github.com/repos/{repo_full_name}/contents\"\n    r = requests.get(url, headers=HEADERS)\n    if r.status_code != 200:\n        print(f\"  ‚ö†Ô∏è Couldn't list {repo_full_name}: HTTP {r.status_code}\")\n        return",
        "detail": "fetchers.github_fetch",
        "documentation": {}
    },
    {
        "label": "authenticate_kaggle",
        "kind": 2,
        "importPath": "fetchers.kaggle",
        "description": "fetchers.kaggle",
        "peekOfCode": "def authenticate_kaggle():\n    \"\"\"\n    Authenticate with Kaggle using the kaggle.json file.\n    The `kaggle.json` file should be placed in the path: ~/.kaggle/kaggle.json\n    \"\"\"\n    # Check if kaggle.json exists in the default location\n    kaggle_json_path = os.path.expanduser('~/.kaggle/kaggle.json')\n    if not os.path.exists(kaggle_json_path):\n        print(\"‚ùå Kaggle API key not found! Please place kaggle.json in ~/.kaggle/\")\n        return None",
        "detail": "fetchers.kaggle",
        "documentation": {}
    },
    {
        "label": "download_kaggle_code_samples",
        "kind": 2,
        "importPath": "fetchers.kaggle",
        "description": "fetchers.kaggle",
        "peekOfCode": "def download_kaggle_code_samples(dataset_name, download_path):\n    \"\"\"\n    Download the files of a Kaggle dataset and unzip them into the specified path.\n    \"\"\"\n    api = authenticate_kaggle()\n    if api is None:\n        return  # Exit if authentication fails\n    # Download the dataset and unzip\n    print(f\"üîÑ Downloading {dataset_name} dataset...\")\n    api.dataset_download_files(dataset_name, path=download_path, unzip=True)",
        "detail": "fetchers.kaggle",
        "documentation": {}
    },
    {
        "label": "get_ast_structure",
        "kind": 2,
        "importPath": "language_parsers.ast_parser",
        "description": "language_parsers.ast_parser",
        "peekOfCode": "def get_ast_structure(code):\n    # Returns AST structure, ignoring variable names, function names, and argument names. \n    try:\n        tree = ast.parse(code)\n        for node in ast.walk(tree):\n            # Ignore function name\n            if isinstance(node, ast.FunctionDef):\n                node.name = \"FUNC\"\n                for arg in node.args.args:\n                    arg.arg = \"VAR\"  # Replace argument names with VAR",
        "detail": "language_parsers.ast_parser",
        "documentation": {}
    },
    {
        "label": "get_cpp_structure",
        "kind": 2,
        "importPath": "language_parsers.cpp_parser",
        "description": "language_parsers.cpp_parser",
        "peekOfCode": "def get_cpp_structure(code):\n    try:\n        # Remove comments\n        code = re.sub(r'//.*?$|/\\*.*?\\*/', '', code, flags=re.DOTALL | re.MULTILINE)\n        # Replace variable names and literals\n        code = re.sub(r'\\bint\\b|\\bfloat\\b|\\bdouble\\b|\\bchar\\b|\\bstring\\b', 'TYPE', code)\n        code = re.sub(r'\\\".*?\\\"|\\'.*?\\'|\\b\\d+\\b', 'CONST', code)\n        code = re.sub(r'\\b\\w+\\s*(?=\\()', 'FUNC', code)  # function calls\n        code = re.sub(r'\\b\\w+\\b', 'VAR', code)  # replace remaining words with VAR\n        return code",
        "detail": "language_parsers.cpp_parser",
        "documentation": {}
    },
    {
        "label": "get_java_structure",
        "kind": 2,
        "importPath": "language_parsers.java_parser",
        "description": "language_parsers.java_parser",
        "peekOfCode": "def get_java_structure(code):\n    try:\n        # Remove single-line and multi-line comments\n        code = re.sub(r'//.*?$|/\\*.*?\\*/', '', code, flags=re.DOTALL | re.MULTILINE)\n        # Replace types and literals\n        code = re.sub(r'\\bint\\b|\\bfloat\\b|\\bString\\b|\\bdouble\\b|\\bchar\\b', 'TYPE', code)\n        code = re.sub(r'\\\".*?\\\"|\\'.*?\\'|\\b\\d+\\b', 'CONST', code)\n        code = re.sub(r'\\b\\w+\\s*(?=\\()', 'FUNC', code)  # function calls\n        code = re.sub(r'\\b\\w+\\b', 'VAR', code)\n        return code",
        "detail": "language_parsers.java_parser",
        "documentation": {}
    },
    {
        "label": "sort_blocks",
        "kind": 2,
        "importPath": "reference_codes.python.vinta_awesome-python_sort",
        "description": "reference_codes.python.vinta_awesome-python_sort",
        "peekOfCode": "def sort_blocks():\n    # First, we load the current README into memory\n    with open('README.md', 'r') as read_me_file:\n        read_me = read_me_file.read()\n    # Separating the 'table of contents' from the contents (blocks)\n    table_of_contents = ''.join(read_me.split('- - -')[0])\n    blocks = ''.join(read_me.split('- - -')[1]).split('\\n# ')\n    for i in range(len(blocks)):\n        if i == 0:\n            blocks[i] = blocks[i] + '\\n'",
        "detail": "reference_codes.python.vinta_awesome-python_sort",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "reference_codes.python.vinta_awesome-python_sort",
        "description": "reference_codes.python.vinta_awesome-python_sort",
        "peekOfCode": "def main():\n    # First, we load the current README into memory as an array of lines\n    with open('README.md', 'r') as read_me_file:\n        read_me = read_me_file.readlines()\n    # Then we cluster the lines together as blocks\n    # Each block represents a collection of lines that should be sorted\n    # This was done by assuming only links ([...](...)) are meant to be sorted\n    # Clustering is done by indentation\n    blocks = []\n    last_indent = None",
        "detail": "reference_codes.python.vinta_awesome-python_sort",
        "documentation": {}
    },
    {
        "label": "fresh",
        "kind": 2,
        "importPath": "reference_codes.python_0",
        "description": "reference_codes.python_0",
        "peekOfCode": "def fresh(self) -> bool:\n        \"\"\"\n        Ê£ÄÊü•ËØ∑Ê±ÇÁºìÂ≠òÊòØÂê¶‚ÄúÊñ∞È≤ú‚ÄùÔºå‰πüÂ∞±ÊòØÂÜÖÂÆπÊ≤°ÊúâÊîπÂèò„ÄÇ\n        Ê≠§ÊñπÊ≥ïÁî®‰∫é If-None-Match / ETag, Âíå If-Modified-Since Âíå Last-Modified ‰πãÈó¥ÁöÑÁºìÂ≠òÂçèÂïÜ„ÄÇ\n        Âú®ËÆæÁΩÆ‰∏Ä‰∏™ÊàñÂ§ö‰∏™Ëøô‰∫õÂìçÂ∫îÂ§¥ÂêéÂ∫îËØ•ÂºïÁî®ÂÆÉ„ÄÇ\n        \"\"\"\n        method_str = self.method\n        if method_str != 'GET' and method_str != 'HEAD':\n            return False\n        s = self.ctx.status",
        "detail": "reference_codes.python_0",
        "documentation": {}
    },
    {
        "label": "attrib",
        "kind": 2,
        "importPath": "reference_codes.python_1",
        "description": "reference_codes.python_1",
        "peekOfCode": "def attrib(self):\n        \"\"\"\n        General XML element attributes for a seismic source, as a dict.\n        \"\"\"\n        return dict([\n            ('id', str(self.id)),\n            ('name', str(self.name)),\n            ('tectonicRegion', str(self.trt)),\n        ])",
        "detail": "reference_codes.python_1",
        "documentation": {}
    },
    {
        "label": "update_views",
        "kind": 2,
        "importPath": "reference_codes.python_2",
        "description": "reference_codes.python_2",
        "peekOfCode": "def update_views(self):\n        \"\"\"Update stats views.\"\"\"\n        # Call the father's method\n        super(Plugin, self).update_views()\n        # Add specifics informations\n        # Alert and log\n        self.views['used']['decoration'] = self.get_alert_log(self.stats['used'], maximum=self.stats['total'])",
        "detail": "reference_codes.python_2",
        "documentation": {}
    },
    {
        "label": "add",
        "kind": 2,
        "importPath": "reference_codes.python_3",
        "description": "reference_codes.python_3",
        "peekOfCode": "def add(cls, model, commit=True):\n        \"\"\"Adds a model instance to session and commits the\n        transaction.\n        Args:\n            model: The instance to add.\n        Examples:\n            >>> customer = Customer.new(name=\"hari\", email=\"hari@gmail.com\")\n            >>> Customer.add(customer)\n            hari@gmail.com\n        \"\"\"",
        "detail": "reference_codes.python_3",
        "documentation": {}
    },
    {
        "label": "bucket_type_key",
        "kind": 2,
        "importPath": "reference_codes.python_4",
        "description": "reference_codes.python_4",
        "peekOfCode": "def bucket_type_key(bucket_type):\n    \"\"\"\n    Registers a function that calculates test item key for the specified bucket type.\n    \"\"\"\n    def decorator(f):\n        @functools.wraps(f)\n        def wrapped(item, session):\n            key = f(item)\n            if session is not None:\n                for handler in session.random_order_bucket_type_key_handlers:",
        "detail": "reference_codes.python_4",
        "documentation": {}
    },
    {
        "label": "normalize_commit_message",
        "kind": 2,
        "importPath": "reference_codes.python_5",
        "description": "reference_codes.python_5",
        "peekOfCode": "def normalize_commit_message(commit_message):\n    \"\"\"\n    Return a tuple of title and body from the commit message\n    \"\"\"\n    split_commit_message = commit_message.split(\"\\n\")\n    title = split_commit_message[0]\n    body = \"\\n\".join(split_commit_message[1:])\n    return title, body.lstrip(\"\\n\")",
        "detail": "reference_codes.python_5",
        "documentation": {}
    },
    {
        "label": "get_properties_from_graph",
        "kind": 2,
        "importPath": "reference_codes.python_7",
        "description": "reference_codes.python_7",
        "peekOfCode": "def get_properties_from_graph(graph):\n        \"\"\"\n        Wrapper for RDFLib.graph.predicates() that returns a unique set\n        :param graph: RDFLib.graph\n        :return: set, set of properties\n        \"\"\"\n        # collapse to single list\n        property_set = set()\n        for row in graph.predicates():\n            property_set.add(row)",
        "detail": "reference_codes.python_7",
        "documentation": {}
    },
    {
        "label": "grad",
        "kind": 2,
        "importPath": "reference_codes.python_8",
        "description": "reference_codes.python_8",
        "peekOfCode": "def grad(self, X, lenscale=None):\n        r\"\"\"\n        Get the gradients of this basis w.r.t.\\ the length scale.\n        Parameters\n        ----------\n        x: ndarray\n            (n, d) array of observations where n is the number of samples, and\n            d is the dimensionality of x.\n        lenscale: scalar or ndarray\n            scalar or array of shape (d,) length scales (one for each dimension",
        "detail": "reference_codes.python_8",
        "documentation": {}
    },
    {
        "label": "root_item_selected",
        "kind": 2,
        "importPath": "reference_codes.python_9",
        "description": "reference_codes.python_9",
        "peekOfCode": "def root_item_selected(self, item):\n        \"\"\"Root item has been selected: expanding it and collapsing others\"\"\"\n        if self.show_all_files:\n            return\n        for root_item in self.get_top_level_items():\n            if root_item is item:\n                self.expandItem(root_item)\n            else:\n                self.collapseItem(root_item)",
        "detail": "reference_codes.python_9",
        "documentation": {}
    },
    {
        "label": "add",
        "kind": 2,
        "importPath": "uploads.user_code",
        "description": "uploads.user_code",
        "peekOfCode": "def add(cls, model, commit=True):\n        \"\"\"Adds a model instance to session and commits the\n        transaction.\n        Args:\n            model: The instance to add.\n        Examples:\n            >>> customer = Customer.new(name=\"hari\", email=\"hari@gmail.com\")\n            >>> Customer.add(customer)\n            hari@gmail.com\n        \"\"\"",
        "detail": "uploads.user_code",
        "documentation": {}
    },
    {
        "label": "calculate_similarity",
        "kind": 2,
        "importPath": "utils.similarity_checker",
        "description": "utils.similarity_checker",
        "peekOfCode": "def calculate_similarity(code1, code2):\n    return round(SequenceMatcher(None, code1, code2).ratio() * 100, 2)",
        "detail": "utils.similarity_checker",
        "documentation": {}
    },
    {
        "label": "PlagiarismCheck",
        "kind": 6,
        "importPath": "api",
        "description": "api",
        "peekOfCode": "class PlagiarismCheck(Resource):\n    def post(self):\n        try:\n            uploaded_file = request.files['user_code']\n            filename = uploaded_file.filename\n            if not filename:\n                return jsonify({\"status\": \"error\", \"message\": \"No file uploaded.\"})\n            # Save uploaded file\n            user_code_path = os.path.join('uploads', filename)\n            uploaded_file.save(user_code_path)",
        "detail": "api",
        "documentation": {}
    },
    {
        "label": "app",
        "kind": 5,
        "importPath": "api",
        "description": "api",
        "peekOfCode": "app = Flask(__name__)\napi = Api(app)\nclass PlagiarismCheck(Resource):\n    def post(self):\n        try:\n            uploaded_file = request.files['user_code']\n            filename = uploaded_file.filename\n            if not filename:\n                return jsonify({\"status\": \"error\", \"message\": \"No file uploaded.\"})\n            # Save uploaded file",
        "detail": "api",
        "documentation": {}
    },
    {
        "label": "api",
        "kind": 5,
        "importPath": "api",
        "description": "api",
        "peekOfCode": "api = Api(app)\nclass PlagiarismCheck(Resource):\n    def post(self):\n        try:\n            uploaded_file = request.files['user_code']\n            filename = uploaded_file.filename\n            if not filename:\n                return jsonify({\"status\": \"error\", \"message\": \"No file uploaded.\"})\n            # Save uploaded file\n            user_code_path = os.path.join('uploads', filename)",
        "detail": "api",
        "documentation": {}
    },
    {
        "label": "LanguageForm",
        "kind": 6,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "class LanguageForm(FlaskForm):\n    language = SelectField(\n        'Programming Language',\n        choices=[('cpp', 'C++'), ('py', 'Python'), ('java', 'Java')],\n        validators=[DataRequired()]\n    )\n# # Streamlit interface\n# st.title(\"Compare Your Code with Kaggle Code\")\n# # Upload the user's code file\n# uploaded_file = st.file_uploader(\"Upload your code file\", type=[\"py\", \"java\", \"cpp\"])",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "fetch_codeforces_info",
        "kind": 2,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "def fetch_codeforces_info(username):\n    url = f\"https://codeforces.com/api/user.info?handles={username}\"\n    response = requests.get(url)\n    data = response.json()\n    if data['status'] == 'OK':\n        user = data['result'][0]\n        return {\n            'handle': user['handle'],\n            'rank': user['rank'],\n            'rating': user['rating'],",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "fetch_gfg_code",
        "kind": 2,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "def fetch_gfg_code(username):\n    url = f\"https://gfg-api-fefa.onrender.com/{username}\"\n    response = requests.get(url)\n    return response.json() if response.status_code == 200 else None\n# Fetch CodeSearchNet Code Snippets\ndef fetch_reference_codes(language, max_files=10):\n    dataset = load_dataset(\"code_search_net\", language, split=\"train\")\n    samples = dataset.shuffle(seed=42).select(range(max_files))\n    return [sample['code'] for sample in samples]\n@app.route(\"/\", methods=[\"GET\", \"POST\"])",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "fetch_reference_codes",
        "kind": 2,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "def fetch_reference_codes(language, max_files=10):\n    dataset = load_dataset(\"code_search_net\", language, split=\"train\")\n    samples = dataset.shuffle(seed=42).select(range(max_files))\n    return [sample['code'] for sample in samples]\n@app.route(\"/\", methods=[\"GET\", \"POST\"])\ndef home():\n    results = None\n    overall_avg = 0\n    precision = recall = f1 = 0\n    pie_data = {\"original\": 0, \"plagiarized\": 0}",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "home",
        "kind": 2,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "def home():\n    results = None\n    overall_avg = 0\n    precision = recall = f1 = 0\n    pie_data = {\"original\": 0, \"plagiarized\": 0}\n    predictions = []\n    user_code_path = \"\"\n    form = LanguageForm()\n    if form.validate_on_submit():\n        selected_language = form.language.data",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "download_report",
        "kind": 2,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "def download_report():\n    overall_avg = report_data[\"overall_avg\"]\n    precision = report_data[\"precision\"]\n    recall = report_data[\"recall\"]\n    f1 = report_data[\"f1\"]\n    accuracy = report_data[\"accuracy\"]\n    confusion_matrix = report_data[\"confusion_matrix\"]\n    # Create pie chart\n    pie_labels = ['Original', 'Plagiarized']\n    pie_sizes = [100 - overall_avg, overall_avg]",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "codeforces",
        "kind": 2,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "def codeforces():\n    user_info = None\n    if request.method == \"POST\":\n        username = request.form.get(\"username\")\n        if username:\n            user_info = fetch_codeforces_info(username)\n    return render_template(\"codeforces.html\", user_info=user_info)\n@app.route(\"/gfg\", methods=[\"POST\"])\ndef gfg():\n    username = request.form.get(\"gfg_username\")",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "gfg",
        "kind": 2,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "def gfg():\n    username = request.form.get(\"gfg_username\")\n    user_data = fetch_gfg_code(username)\n    if user_data:\n        return render_template(\"gfg.html\", user_data=user_data)\n    else:\n        return \"GFG user not found\", 404\n@app.route(\"/codesearchnet\", methods=[\"POST\"])\ndef codesearchnet():\n    language = request.form.get(\"language\")",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "codesearchnet",
        "kind": 2,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "def codesearchnet():\n    language = request.form.get(\"language\")\n    code_snippets = fetch_reference_codes(language)\n    return render_template(\"codesearchnet.html\", code_snippets=code_snippets)\nif __name__ == \"__main__\":\n    app.run(debug=True)",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "report_data",
        "kind": 5,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "report_data = {\n    \"overall_avg\": 0,\n    \"precision\": 85,\n    \"recall\": 80,\n    \"f1\": 82.5,\n    \"accuracy\": 83,\n    \"confusion_matrix\": [[50, 10], [5, 35]]\n}\n# import streamlit as st\n# from kaggle import download_kaggle_code_samples",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "app",
        "kind": 5,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "app = Flask(__name__)\nUPLOAD_FOLDER = 'uploads/'\nREPORT_PATH = 'report.csv'\napp.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\napp.config['SECRET_KEY'] = os.environ.get('SECRET_KEY')\nos.makedirs(UPLOAD_FOLDER, exist_ok=True)\nclass LanguageForm(FlaskForm):\n    language = SelectField(\n        'Programming Language',\n        choices=[('cpp', 'C++'), ('py', 'Python'), ('java', 'Java')],",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "UPLOAD_FOLDER",
        "kind": 5,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "UPLOAD_FOLDER = 'uploads/'\nREPORT_PATH = 'report.csv'\napp.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\napp.config['SECRET_KEY'] = os.environ.get('SECRET_KEY')\nos.makedirs(UPLOAD_FOLDER, exist_ok=True)\nclass LanguageForm(FlaskForm):\n    language = SelectField(\n        'Programming Language',\n        choices=[('cpp', 'C++'), ('py', 'Python'), ('java', 'Java')],\n        validators=[DataRequired()]",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "REPORT_PATH",
        "kind": 5,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "REPORT_PATH = 'report.csv'\napp.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\napp.config['SECRET_KEY'] = os.environ.get('SECRET_KEY')\nos.makedirs(UPLOAD_FOLDER, exist_ok=True)\nclass LanguageForm(FlaskForm):\n    language = SelectField(\n        'Programming Language',\n        choices=[('cpp', 'C++'), ('py', 'Python'), ('java', 'Java')],\n        validators=[DataRequired()]\n    )",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "app.config['UPLOAD_FOLDER']",
        "kind": 5,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\napp.config['SECRET_KEY'] = os.environ.get('SECRET_KEY')\nos.makedirs(UPLOAD_FOLDER, exist_ok=True)\nclass LanguageForm(FlaskForm):\n    language = SelectField(\n        'Programming Language',\n        choices=[('cpp', 'C++'), ('py', 'Python'), ('java', 'Java')],\n        validators=[DataRequired()]\n    )\n# # Streamlit interface",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "app.config['SECRET_KEY']",
        "kind": 5,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "app.config['SECRET_KEY'] = os.environ.get('SECRET_KEY')\nos.makedirs(UPLOAD_FOLDER, exist_ok=True)\nclass LanguageForm(FlaskForm):\n    language = SelectField(\n        'Programming Language',\n        choices=[('cpp', 'C++'), ('py', 'Python'), ('java', 'Java')],\n        validators=[DataRequired()]\n    )\n# # Streamlit interface\n# st.title(\"Compare Your Code with Kaggle Code\")",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "CFGGenerator",
        "kind": 6,
        "importPath": "cfg_generator",
        "description": "cfg_generator",
        "peekOfCode": "class CFGGenerator(ast.NodeVisitor):\n    def __init__(self):\n        self.graph = nx.DiGraph()\n        self.current_node = 0\n        self.counter = 0\n    def add_node(self, label):\n        \"\"\"Add a node to the graph with a given label.\"\"\"\n        self.counter += 1\n        self.graph.add_node(self.counter, label=label)\n        if self.current_node != 0:",
        "detail": "cfg_generator",
        "documentation": {}
    },
    {
        "label": "generate_cfg",
        "kind": 2,
        "importPath": "cfg_generator",
        "description": "cfg_generator",
        "peekOfCode": "def generate_cfg(code):\n    \"\"\"Generate the control flow graph (CFG) for the given code.\"\"\"\n    try:\n        tree = ast.parse(code)\n        cfg_gen = CFGGenerator()\n        cfg_gen.visit(tree)\n        return cfg_gen.graph\n    except Exception as e:\n        return f\"Error generating CFG: {str(e)}\"",
        "detail": "cfg_generator",
        "documentation": {}
    },
    {
        "label": "matrix_multiply",
        "kind": 2,
        "importPath": "code1",
        "description": "code1",
        "peekOfCode": "def matrix_multiply(A, B):\n    \"\"\"Performs matrix multiplication with basic loops.\"\"\"\n    try:\n        # ‚úÖ Initialize result matrix with zeros\n        result = [[0 for _ in range(len(B[0]))] for _ in range(len(A))]\n        # ‚úÖ Matrix multiplication logic\n        for i in range(len(A)):\n            for j in range(len(B[0])):\n                for k in range(len(B)):\n                    result[i][j] += A[i][k] * B[k][j]",
        "detail": "code1",
        "documentation": {}
    },
    {
        "label": "matrix_multiply",
        "kind": 2,
        "importPath": "code2",
        "description": "code2",
        "peekOfCode": "def matrix_multiply(A, B):\n    \"\"\"Performs matrix multiplication of A and B.\"\"\"\n    try:\n        # Initialize the result matrix with zeros\n        result = [[0 for _ in range(len(B[0]))] for _ in range(len(A))]\n        # Matrix multiplication logic\n        for i in range(len(A)):\n            for j in range(len(B[0])):\n                for k in range(len(B)):\n                    result[i][j] += A[i][k] * B[k][j]",
        "detail": "code2",
        "documentation": {}
    },
    {
        "label": "run_test_cases",
        "kind": 2,
        "importPath": "code2",
        "description": "code2",
        "peekOfCode": "def run_test_cases():\n    \"\"\"Runs test cases for matrix_multiply.\"\"\"\n    # Test Case 1: Basic 2x2 matrix multiplication\n    A1 = [[1, 2], [3, 4]]\n    B1 = [[5, 6], [7, 8]]\n    expected1 = [[19, 22], [43, 50]]\n    result1 = matrix_multiply(A1, B1)\n    if result1 == expected1:\n        print(\"‚úÖ Test Case 1 Passed!\")\n    else:",
        "detail": "code2",
        "documentation": {}
    },
    {
        "label": "is_plagiarized",
        "kind": 2,
        "importPath": "compare",
        "description": "compare",
        "peekOfCode": "def is_plagiarized(similarity_score, threshold=0.7):\n    \"\"\"Returns True if similarity score is above threshold.\"\"\"\n    return similarity_score >= threshold\ndef compare_ast_structures(user_code, reference_code):\n    \"\"\"Compare AST structures by dumping and checking string equality.\"\"\"\n    try:\n        ast_user = get_ast_structure(user_code)\n        ast_ref = get_ast_structure(reference_code)\n        return ast.dump(ast_user) == ast.dump(ast_ref)\n    except Exception:",
        "detail": "compare",
        "documentation": {}
    },
    {
        "label": "compare_ast_structures",
        "kind": 2,
        "importPath": "compare",
        "description": "compare",
        "peekOfCode": "def compare_ast_structures(user_code, reference_code):\n    \"\"\"Compare AST structures by dumping and checking string equality.\"\"\"\n    try:\n        ast_user = get_ast_structure(user_code)\n        ast_ref = get_ast_structure(reference_code)\n        return ast.dump(ast_user) == ast.dump(ast_ref)\n    except Exception:\n        return False\ndef compare_cfg(user_code, reference_code):\n    \"\"\"Compare Control Flow Graphs (CFGs) for two code snippets.\"\"\"",
        "detail": "compare",
        "documentation": {}
    },
    {
        "label": "compare_cfg",
        "kind": 2,
        "importPath": "compare",
        "description": "compare",
        "peekOfCode": "def compare_cfg(user_code, reference_code):\n    \"\"\"Compare Control Flow Graphs (CFGs) for two code snippets.\"\"\"\n    cfg_user = generate_cfg(user_code)\n    cfg_ref = generate_cfg(reference_code)\n    if isinstance(cfg_user, str) or isinstance(cfg_ref, str):\n        return False\n    return nx.is_isomorphic(cfg_user, cfg_ref)\ndef calculate_synthetic_similarity(user_code, reference_code):\n    \"\"\"Calculate synthetic similarity by normalizing, tokenizing, and comparing hashes.\"\"\"\n    normalized_user = normalize_code(user_code)",
        "detail": "compare",
        "documentation": {}
    },
    {
        "label": "calculate_synthetic_similarity",
        "kind": 2,
        "importPath": "compare",
        "description": "compare",
        "peekOfCode": "def calculate_synthetic_similarity(user_code, reference_code):\n    \"\"\"Calculate synthetic similarity by normalizing, tokenizing, and comparing hashes.\"\"\"\n    normalized_user = normalize_code(user_code)\n    normalized_ref = normalize_code(reference_code)\n    normalized_similarity = SequenceMatcher(None, normalized_user, normalized_ref).ratio()\n    tokens_user = tokenize_code(user_code)\n    tokens_ref = tokenize_code(reference_code)\n    token_match = tokens_user == tokens_ref\n    hash_user = hash_code(user_code)\n    hash_ref = hash_code(reference_code)",
        "detail": "compare",
        "documentation": {}
    },
    {
        "label": "calculate_structural_similarity",
        "kind": 2,
        "importPath": "compare",
        "description": "compare",
        "peekOfCode": "def calculate_structural_similarity(user_code, reference_code):\n    \"\"\"Calculate structural similarity using AST and CFG.\"\"\"\n    ast_match = compare_ast_structures(user_code, reference_code)\n    cfg_match = compare_cfg(user_code, reference_code)\n    structural_similarity = 0.5 * int(ast_match) + 0.5 * int(cfg_match)\n    return round(structural_similarity, 4)\ndef run_test_cases(code, test_cases):\n    \"\"\"Executes the code with given test cases and returns the results.\"\"\"\n    results = []\n    for case in test_cases:",
        "detail": "compare",
        "documentation": {}
    },
    {
        "label": "run_test_cases",
        "kind": 2,
        "importPath": "compare",
        "description": "compare",
        "peekOfCode": "def run_test_cases(code, test_cases):\n    \"\"\"Executes the code with given test cases and returns the results.\"\"\"\n    results = []\n    for case in test_cases:\n        inputs, expected_output = case[\"input\"], case[\"expected_output\"]\n        try:\n            exec_globals = {}\n            exec(code, exec_globals)\n            func_name = [name for name in exec_globals if not name.startswith(\"__\")][0]\n            func = exec_globals[func_name]",
        "detail": "compare",
        "documentation": {}
    },
    {
        "label": "calculate_behavioral_similarity",
        "kind": 2,
        "importPath": "compare",
        "description": "compare",
        "peekOfCode": "def calculate_behavioral_similarity(user_code, reference_code, test_cases):\n    \"\"\"Compare code behavior based on input-output similarity and execution time.\"\"\"\n    results_user = run_test_cases(user_code, test_cases)\n    results_ref = run_test_cases(reference_code, test_cases)\n    matching_outputs = 0\n    total_cases = len(test_cases)\n    time_diff_sum = 0\n    for (output_user, time_user), (output_ref, time_ref) in zip(results_user, results_ref):\n        if output_user == output_ref:\n            matching_outputs += 1",
        "detail": "compare",
        "documentation": {}
    },
    {
        "label": "extract_similarity_features",
        "kind": 2,
        "importPath": "compare",
        "description": "compare",
        "peekOfCode": "def extract_similarity_features(results_dict):\n    \"\"\"Extract [synthetic, structural, behavioral] features for ML prediction.\"\"\"\n    return [\n        results_dict[\"Synthetic Similarity\"],\n        results_dict[\"Structural Similarity\"],\n        results_dict[\"Behavioral Similarity\"]\n    ]\ndef compare_codes(user_code, reference_code, test_cases=None, verbose=False):\n    \"\"\"Compares two codes using multiple techniques and returns similarity scores.\"\"\"\n    user_code = preprocess_code(user_code)",
        "detail": "compare",
        "documentation": {}
    },
    {
        "label": "compare_codes",
        "kind": 2,
        "importPath": "compare",
        "description": "compare",
        "peekOfCode": "def compare_codes(user_code, reference_code, test_cases=None, verbose=False):\n    \"\"\"Compares two codes using multiple techniques and returns similarity scores.\"\"\"\n    user_code = preprocess_code(user_code)\n    reference_code = preprocess_code(reference_code)\n    synthetic_similarity = calculate_synthetic_similarity(user_code, reference_code)\n    structural_similarity = calculate_structural_similarity(user_code, reference_code)\n    if test_cases:\n        behavioral_similarity = calculate_behavioral_similarity(user_code, reference_code, test_cases)\n    else:\n        behavioral_similarity = 0.0",
        "detail": "compare",
        "documentation": {}
    },
    {
        "label": "evaluate_plagiarism_detection",
        "kind": 2,
        "importPath": "evaluate",
        "description": "evaluate",
        "peekOfCode": "def evaluate_plagiarism_detection(user_file_path, reference_file_paths, labels):\n    print(f\"\\nEvaluating plagiarism for user file: {user_file_path}\\n\")\n    y_true, y_pred = [], []\n    # Load and preprocess user code\n    user_code_raw = load_code(user_file_path)\n    user_code_processed = preprocess_code(user_code_raw)\n    tokenized_user_code = tokenize_code(user_code_processed)\n    normalized_user_code = normalize_code(tokenized_user_code)\n    similarities = {}\n    for ref_file_path, label in zip(reference_file_paths, labels):",
        "detail": "evaluate",
        "documentation": {}
    },
    {
        "label": "evaluate_metrics",
        "kind": 2,
        "importPath": "evaluate",
        "description": "evaluate",
        "peekOfCode": "def evaluate_metrics(y_true, y_pred):\n    cm = confusion_matrix(y_true, y_pred)\n    print(\"Confusion Matrix:\\n\", cm)\n    print(f\"Accuracy:  {accuracy_score(y_true, y_pred):.4f}\")\n    print(f\"Precision: {precision_score(y_true, y_pred):.4f}\")\n    print(f\"Recall:    {recall_score(y_true, y_pred):.4f}\")\n    print(f\"F1 Score:  {f1_score(y_true, y_pred):.4f}\")\n    fpr, tpr, _ = roc_curve(y_true, y_pred)\n    roc_auc = auc(fpr, tpr)\n    plt.figure()",
        "detail": "evaluate",
        "documentation": {}
    },
    {
        "label": "plot_similarity_pie_chart",
        "kind": 2,
        "importPath": "evaluate",
        "description": "evaluate",
        "peekOfCode": "def plot_similarity_pie_chart(similarities):\n    labels = [os.path.basename(ref) for ref in similarities.keys()]\n    scores = list(similarities.values())\n    plt.figure(figsize=(6, 6))\n    plt.pie(scores, labels=labels, autopct='%1.1f%%', startangle=90, colors=plt.cm.Paired.colors)\n    plt.title(\"Similarity Scores Breakdown\")\n    plt.axis('equal')  # Equal aspect ratio ensures the pie is circular.\n    plt.show()",
        "detail": "evaluate",
        "documentation": {}
    },
    {
        "label": "generate_plagiarized_code",
        "kind": 2,
        "importPath": "generate_plagiarized",
        "description": "generate_plagiarized",
        "peekOfCode": "def generate_plagiarized_code(original_code):\n    \"\"\"Generate a plagiarized version of the original code with modifications.\"\"\"\n    prompt = f\"Rewrite the following code with different variable names, loop structures, and formatting:\\n\\n{original_code}\"\n    try:\n        response = openai.Completion.create(\n            model=\"gpt-4\",\n            prompt=prompt,\n            max_tokens=500  # You can adjust max_tokens as needed\n        )\n        return response.choices[0].text.strip()  # Return the modified code",
        "detail": "generate_plagiarized",
        "documentation": {}
    },
    {
        "label": "openai.api_key",
        "kind": 5,
        "importPath": "generate_plagiarized",
        "description": "generate_plagiarized",
        "peekOfCode": "openai.api_key = os.getenv(\"sk-QpabguAmdr7EzfzEeXe7TxBvByOkulXVpq_vlEM0llT3BlbkFJUkuinrIuRV50If9G-ViPU5vrRUUqIJiQcvQqVzjWIA\")\ndef generate_plagiarized_code(original_code):\n    \"\"\"Generate a plagiarized version of the original code with modifications.\"\"\"\n    prompt = f\"Rewrite the following code with different variable names, loop structures, and formatting:\\n\\n{original_code}\"\n    try:\n        response = openai.Completion.create(\n            model=\"gpt-4\",\n            prompt=prompt,\n            max_tokens=500  # You can adjust max_tokens as needed\n        )",
        "detail": "generate_plagiarized",
        "documentation": {}
    },
    {
        "label": "PDF",
        "kind": 6,
        "importPath": "generate_report",
        "description": "generate_report",
        "peekOfCode": "class PDF(FPDF):\n    def header(self):\n        self.set_font(\"Arial\", \"B\", 16)\n        self.cell(0, 10, \"Code Plagiarism Report\", 0, 1, \"C\")\n        self.ln(5)\n    def add_image(self, path, title):\n        if os.path.exists(path):\n            self.set_font(\"Arial\", \"B\", 12)\n            self.cell(0, 10, title, ln=True)\n            self.image(path, w=180)",
        "detail": "generate_report",
        "documentation": {}
    },
    {
        "label": "generate_pdf_report",
        "kind": 2,
        "importPath": "generate_report",
        "description": "generate_report",
        "peekOfCode": "def generate_pdf_report(final_score, precision, recall, f1, accuracy, confusion_matrix, report_path=\"plagiarism_report.pdf\"):\n    # Generate pie chart\n    pie_labels = ['Original', 'Plagiarized']\n    pie_sizes = [100 - final_score, final_score]\n    pie_colors = ['#4CAF50', '#F44336']\n    plt.figure(figsize=(4, 4))\n    plt.pie(pie_sizes, labels=pie_labels, colors=pie_colors, autopct='%1.1f%%', startangle=140)\n    plt.axis('equal')\n    pie_path = \"static/pie_chart.png\"\n    plt.savefig(pie_path)",
        "detail": "generate_report",
        "documentation": {}
    },
    {
        "label": "hash_code",
        "kind": 2,
        "importPath": "hash_similarity",
        "description": "hash_similarity",
        "peekOfCode": "def hash_code(code):\n    \"\"\" Returns the hash fingerprint of the code. \"\"\"\n    return hashlib.sha256(code.encode()).hexdigest()",
        "detail": "hash_similarity",
        "documentation": {}
    },
    {
        "label": "ensure_dirs",
        "kind": 2,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "def ensure_dirs():\n    os.makedirs(\"uploads\", exist_ok=True)\n    os.makedirs(\"reference_codes/python\", exist_ok=True)\n    os.makedirs(\"reference_codes/java\", exist_ok=True)\n    os.makedirs(\"reference_codes/cpp\", exist_ok=True)\ndef main():\n    parser = argparse.ArgumentParser(description=\"Plagiarism Detection CLI\")\n    parser.add_argument(\"--gfg\", help=\"mahakagarwsjn\")\n    parser.add_argument(\"--cf\", help=\"mahakagarwal25\")\n    parser.add_argument(\"--lang\", help=\"Programming language (python/java/cpp)\", default=\"python\")",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "def main():\n    parser = argparse.ArgumentParser(description=\"Plagiarism Detection CLI\")\n    parser.add_argument(\"--gfg\", help=\"mahakagarwsjn\")\n    parser.add_argument(\"--cf\", help=\"mahakagarwal25\")\n    parser.add_argument(\"--lang\", help=\"Programming language (python/java/cpp)\", default=\"python\")\n    parser.add_argument(\"--user_file\", help=\"Path to user code\", default=\"uploads/user_code.py\")\n    # fetch_gemini_code(form.language.data or args.lang)\n    args = parser.parse_args()\n    ensure_dirs()\n    print(\"\\nüì• Fetching Reference Codes...\\n\")",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "normalize_code",
        "kind": 2,
        "importPath": "normalize",
        "description": "normalize",
        "peekOfCode": "def normalize_code(code):\n    \"\"\" Replaces variable names, numbers, and function names with placeholders. \"\"\"\n    code = re.sub(r'\\b[a-zA-Z_][a-zA-Z0-9_]*\\b', 'VAR', code)  # Replace all variable names\n    code = re.sub(r'\\b\\d+\\b', 'NUM', code)  # Replace numbers\n    return code",
        "detail": "normalize",
        "documentation": {}
    },
    {
        "label": "load_code",
        "kind": 2,
        "importPath": "plagiarism_detector",
        "description": "plagiarism_detector",
        "peekOfCode": "def load_code(file_path):\n    \"\"\"Loads code from a file.\"\"\"\n    try:\n        with open(file_path, 'r', encoding='utf-8') as f:\n            return f.read()\n    except Exception as e:\n        return f\"Error loading file {file_path}: {e}\"\ndef preprocess_code(code):\n    \"\"\"Preprocess the code by removing unnecessary whitespaces and comments.\"\"\"\n    # Remove comments",
        "detail": "plagiarism_detector",
        "documentation": {}
    },
    {
        "label": "preprocess_code",
        "kind": 2,
        "importPath": "plagiarism_detector",
        "description": "plagiarism_detector",
        "peekOfCode": "def preprocess_code(code):\n    \"\"\"Preprocess the code by removing unnecessary whitespaces and comments.\"\"\"\n    # Remove comments\n    code = re.sub(r'#.*', '', code)\n    # Remove extra whitespace\n    code = re.sub(r'\\s+', ' ', code).strip()\n    return code\ndef tokenize_code(code):\n    \"\"\"Tokenize the code by splitting by whitespace and removing non-alphanumeric characters.\"\"\"\n    tokens = re.findall(r'\\w+', code)",
        "detail": "plagiarism_detector",
        "documentation": {}
    },
    {
        "label": "tokenize_code",
        "kind": 2,
        "importPath": "plagiarism_detector",
        "description": "plagiarism_detector",
        "peekOfCode": "def tokenize_code(code):\n    \"\"\"Tokenize the code by splitting by whitespace and removing non-alphanumeric characters.\"\"\"\n    tokens = re.findall(r'\\w+', code)\n    return tokens\ndef normalize_code(tokens):\n    \"\"\"Normalize tokens by converting to lowercase.\"\"\"\n    return [token.lower() for token in tokens]\ndef compute_ast(user_code, reference_code):\n    \"\"\"Compute AST similarity between two pieces of code.\"\"\"\n    # A simple placeholder implementation for AST similarity",
        "detail": "plagiarism_detector",
        "documentation": {}
    },
    {
        "label": "normalize_code",
        "kind": 2,
        "importPath": "plagiarism_detector",
        "description": "plagiarism_detector",
        "peekOfCode": "def normalize_code(tokens):\n    \"\"\"Normalize tokens by converting to lowercase.\"\"\"\n    return [token.lower() for token in tokens]\ndef compute_ast(user_code, reference_code):\n    \"\"\"Compute AST similarity between two pieces of code.\"\"\"\n    # A simple placeholder implementation for AST similarity\n    try:\n        user_ast = ast.parse(user_code)\n        ref_ast = ast.parse(reference_code)\n        return compare_ast(user_ast, ref_ast)",
        "detail": "plagiarism_detector",
        "documentation": {}
    },
    {
        "label": "compute_ast",
        "kind": 2,
        "importPath": "plagiarism_detector",
        "description": "plagiarism_detector",
        "peekOfCode": "def compute_ast(user_code, reference_code):\n    \"\"\"Compute AST similarity between two pieces of code.\"\"\"\n    # A simple placeholder implementation for AST similarity\n    try:\n        user_ast = ast.parse(user_code)\n        ref_ast = ast.parse(reference_code)\n        return compare_ast(user_ast, ref_ast)\n    except SyntaxError:\n        return 0.0\ndef compare_ast(user_ast, ref_ast):",
        "detail": "plagiarism_detector",
        "documentation": {}
    },
    {
        "label": "compare_ast",
        "kind": 2,
        "importPath": "plagiarism_detector",
        "description": "plagiarism_detector",
        "peekOfCode": "def compare_ast(user_ast, ref_ast):\n    \"\"\"A basic comparison for AST similarity (you can improve this).\"\"\"\n    return 1.0 if user_ast == ref_ast else 0.0  # Placeholder for AST match\ndef compute_cfg(user_code, reference_code):\n    \"\"\"Compute CFG similarity between two pieces of code.\"\"\"\n    # Placeholder for CFG similarity\n    return 0.8  # Example, can be improved with a CFG parser\ndef compute_hash_similarity(user_code, reference_code):\n    \"\"\"Compute hash similarity based on hash values of code.\"\"\"\n    import hashlib",
        "detail": "plagiarism_detector",
        "documentation": {}
    },
    {
        "label": "compute_cfg",
        "kind": 2,
        "importPath": "plagiarism_detector",
        "description": "plagiarism_detector",
        "peekOfCode": "def compute_cfg(user_code, reference_code):\n    \"\"\"Compute CFG similarity between two pieces of code.\"\"\"\n    # Placeholder for CFG similarity\n    return 0.8  # Example, can be improved with a CFG parser\ndef compute_hash_similarity(user_code, reference_code):\n    \"\"\"Compute hash similarity based on hash values of code.\"\"\"\n    import hashlib\n    user_hash = hashlib.sha256(user_code.encode()).hexdigest()\n    ref_hash = hashlib.sha256(reference_code.encode()).hexdigest()\n    return 1.0 if user_hash == ref_hash else 0.0",
        "detail": "plagiarism_detector",
        "documentation": {}
    },
    {
        "label": "compute_hash_similarity",
        "kind": 2,
        "importPath": "plagiarism_detector",
        "description": "plagiarism_detector",
        "peekOfCode": "def compute_hash_similarity(user_code, reference_code):\n    \"\"\"Compute hash similarity based on hash values of code.\"\"\"\n    import hashlib\n    user_hash = hashlib.sha256(user_code.encode()).hexdigest()\n    ref_hash = hashlib.sha256(reference_code.encode()).hexdigest()\n    return 1.0 if user_hash == ref_hash else 0.0\ndef compute_structural_similarity(user_code, reference_code):\n    \"\"\"Compute structural similarity (example).\"\"\"\n    # Placeholder for structural similarity logic\n    return 0.9",
        "detail": "plagiarism_detector",
        "documentation": {}
    },
    {
        "label": "compute_structural_similarity",
        "kind": 2,
        "importPath": "plagiarism_detector",
        "description": "plagiarism_detector",
        "peekOfCode": "def compute_structural_similarity(user_code, reference_code):\n    \"\"\"Compute structural similarity (example).\"\"\"\n    # Placeholder for structural similarity logic\n    return 0.9\ndef compute_synthetic_similarity(user_code, reference_code):\n    \"\"\"Compute synthetic similarity (example).\"\"\"\n    # Placeholder for synthetic similarity logic\n    return 0.75\ndef compute_behavioral_similarity(user_code, reference_code):\n    \"\"\"Compute behavioral similarity (example).\"\"\"",
        "detail": "plagiarism_detector",
        "documentation": {}
    },
    {
        "label": "compute_synthetic_similarity",
        "kind": 2,
        "importPath": "plagiarism_detector",
        "description": "plagiarism_detector",
        "peekOfCode": "def compute_synthetic_similarity(user_code, reference_code):\n    \"\"\"Compute synthetic similarity (example).\"\"\"\n    # Placeholder for synthetic similarity logic\n    return 0.75\ndef compute_behavioral_similarity(user_code, reference_code):\n    \"\"\"Compute behavioral similarity (example).\"\"\"\n    # Placeholder for behavioral similarity logic\n    return 0.85\ndef compare_file_pair(user_code, reference_code, ext, test_cases=None):\n    \"\"\"Compare user code with reference code.\"\"\"",
        "detail": "plagiarism_detector",
        "documentation": {}
    },
    {
        "label": "compute_behavioral_similarity",
        "kind": 2,
        "importPath": "plagiarism_detector",
        "description": "plagiarism_detector",
        "peekOfCode": "def compute_behavioral_similarity(user_code, reference_code):\n    \"\"\"Compute behavioral similarity (example).\"\"\"\n    # Placeholder for behavioral similarity logic\n    return 0.85\ndef compare_file_pair(user_code, reference_code, ext, test_cases=None):\n    \"\"\"Compare user code with reference code.\"\"\"\n    # Parse code structures based on file extension\n    if ext == '.py':\n        user_structure = ast_parser.get_ast_structure(user_code)\n        ref_structure = ast_parser.get_ast_structure(reference_code)",
        "detail": "plagiarism_detector",
        "documentation": {}
    },
    {
        "label": "compare_file_pair",
        "kind": 2,
        "importPath": "plagiarism_detector",
        "description": "plagiarism_detector",
        "peekOfCode": "def compare_file_pair(user_code, reference_code, ext, test_cases=None):\n    \"\"\"Compare user code with reference code.\"\"\"\n    # Parse code structures based on file extension\n    if ext == '.py':\n        user_structure = ast_parser.get_ast_structure(user_code)\n        ref_structure = ast_parser.get_ast_structure(reference_code)\n    elif ext == '.cpp':\n        user_structure = cpp_parser.get_cpp_structure(user_code)\n        ref_structure = cpp_parser.get_cpp_structure(reference_code)\n    elif ext == '.java':",
        "detail": "plagiarism_detector",
        "documentation": {}
    },
    {
        "label": "detect_plagiarism",
        "kind": 2,
        "importPath": "plagiarism_detector",
        "description": "plagiarism_detector",
        "peekOfCode": "def detect_plagiarism(user_code_path, reference_dir, test_cases=None):\n    \"\"\"Detect plagiarism for a given user code file against all reference files in a directory.\"\"\"\n    user_code = load_code(user_code_path)\n    if user_code.startswith(\"Error loading file\"):\n        return [{\"error\": user_code}], {\"precision\": 0, \"recall\": 0, \"f1\": 0, \"predictions\": []}\n    ext = os.path.splitext(user_code_path)[1].lower()  # Get file extension (e.g., .py, .cpp, .java)\n    results_summary = []\n    predictions = []\n    total = 0\n    plagiarized = 0",
        "detail": "plagiarism_detector",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "plagiarism_detector",
        "description": "plagiarism_detector",
        "peekOfCode": "model = joblib.load(\"rf_model.pkl\")  # Path to your trained Random Forest model\ndef load_code(file_path):\n    \"\"\"Loads code from a file.\"\"\"\n    try:\n        with open(file_path, 'r', encoding='utf-8') as f:\n            return f.read()\n    except Exception as e:\n        return f\"Error loading file {file_path}: {e}\"\ndef preprocess_code(code):\n    \"\"\"Preprocess the code by removing unnecessary whitespaces and comments.\"\"\"",
        "detail": "plagiarism_detector",
        "documentation": {}
    },
    {
        "label": "preprocess_code",
        "kind": 2,
        "importPath": "preprocess",
        "description": "preprocess",
        "peekOfCode": "def preprocess_code(code):\n    \"\"\"Removes comments, extra spaces, and standardizes the code format.\"\"\"\n    code = re.sub(r'#.*', '', code)  # Python single-line comments\n    code = re.sub(r'//.*', '', code)  # C++/Java single-line comments\n    code = re.sub(r'/\\*[\\s\\S]*?\\*/', '', code)  # C++/Java multi-line comments\n    code = re.sub(r'\"\"\"[\\s\\S]*?\"\"\"', '', code)  # Python docstrings\n    code = re.sub(r\"'''[\\s\\S]*?'''\", '', code)  # Python single-quote docstrings\n    code = re.sub(r'\\s+', ' ', code)  # Normalize whitespace\n    return code.strip()",
        "detail": "preprocess",
        "documentation": {}
    },
    {
        "label": "url",
        "kind": 5,
        "importPath": "stackoverflow_scraper",
        "description": "stackoverflow_scraper",
        "peekOfCode": "url = \"https://stackoverflow.com/questions/tagged/python\"\nresponse = requests.get(url)\nsoup = BeautifulSoup(response.text, \"html.parser\")\n# Extract question titles\nfor post in soup.find_all(\"a\", class_=\"question-hyperlink\"):\n    print(post.text)",
        "detail": "stackoverflow_scraper",
        "documentation": {}
    },
    {
        "label": "response",
        "kind": 5,
        "importPath": "stackoverflow_scraper",
        "description": "stackoverflow_scraper",
        "peekOfCode": "response = requests.get(url)\nsoup = BeautifulSoup(response.text, \"html.parser\")\n# Extract question titles\nfor post in soup.find_all(\"a\", class_=\"question-hyperlink\"):\n    print(post.text)",
        "detail": "stackoverflow_scraper",
        "documentation": {}
    },
    {
        "label": "soup",
        "kind": 5,
        "importPath": "stackoverflow_scraper",
        "description": "stackoverflow_scraper",
        "peekOfCode": "soup = BeautifulSoup(response.text, \"html.parser\")\n# Extract question titles\nfor post in soup.find_all(\"a\", class_=\"question-hyperlink\"):\n    print(post.text)",
        "detail": "stackoverflow_scraper",
        "documentation": {}
    },
    {
        "label": "tokenize_code",
        "kind": 2,
        "importPath": "tokenizer",
        "description": "tokenizer",
        "peekOfCode": "def tokenize_code(code):\n    return word_tokenize(code)\n# Example usage\nif __name__ == \"__main__\":\n    text = input(\"Enter some text: \")\n    tokens = tokenize_code(code)\n    print(\"Tokens:\", tokens)",
        "detail": "tokenizer",
        "documentation": {}
    },
    {
        "label": "X",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "X = [\n    [0.9, 0.92, 0.88],  # plagiarized\n    [0.2, 0.3, 0.25],   # not plagiarized\n    [0.85, 0.89, 0.84],  # plagiarized\n    [0.1, 0.2, 0.15]    # not plagiarized\n]\n# Labels (1 = plagiarized, 0 = not plagiarized)\ny = [1, 0, 1, 0]\n# Split the data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "y",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "y = [1, 0, 1, 0]\n# Split the data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n# Initialize the model\nrf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n# Train\nrf_model.fit(X_train, y_train)\n# Predict\ny_pred = rf_model.predict(X_test)\n# Calculate evaluation metrics",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "rf_model",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n# Train\nrf_model.fit(X_train, y_train)\n# Predict\ny_pred = rf_model.predict(X_test)\n# Calculate evaluation metrics\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred)\nrecall = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "y_pred",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "y_pred = rf_model.predict(X_test)\n# Calculate evaluation metrics\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred)\nrecall = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\nconf_matrix = confusion_matrix(y_test, y_pred)\n# Print actual evaluation results\nprint(f\"Accuracy: {accuracy*100:.2f}%\")\nprint(f\"Precision: {precision*100:.2f}%\")",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "accuracy",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "accuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred)\nrecall = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\nconf_matrix = confusion_matrix(y_test, y_pred)\n# Print actual evaluation results\nprint(f\"Accuracy: {accuracy*100:.2f}%\")\nprint(f\"Precision: {precision*100:.2f}%\")\nprint(f\"Recall: {recall*100:.2f}%\")\nprint(f\"F1 Score: {f1*100:.2f}%\")",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "precision",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "precision = precision_score(y_test, y_pred)\nrecall = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\nconf_matrix = confusion_matrix(y_test, y_pred)\n# Print actual evaluation results\nprint(f\"Accuracy: {accuracy*100:.2f}%\")\nprint(f\"Precision: {precision*100:.2f}%\")\nprint(f\"Recall: {recall*100:.2f}%\")\nprint(f\"F1 Score: {f1*100:.2f}%\")\nprint(\"Confusion Matrix:\")",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "recall",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "recall = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\nconf_matrix = confusion_matrix(y_test, y_pred)\n# Print actual evaluation results\nprint(f\"Accuracy: {accuracy*100:.2f}%\")\nprint(f\"Precision: {precision*100:.2f}%\")\nprint(f\"Recall: {recall*100:.2f}%\")\nprint(f\"F1 Score: {f1*100:.2f}%\")\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "f1",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "f1 = f1_score(y_test, y_pred)\nconf_matrix = confusion_matrix(y_test, y_pred)\n# Print actual evaluation results\nprint(f\"Accuracy: {accuracy*100:.2f}%\")\nprint(f\"Precision: {precision*100:.2f}%\")\nprint(f\"Recall: {recall*100:.2f}%\")\nprint(f\"F1 Score: {f1*100:.2f}%\")\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)\nprint(np.array([[50, 10], [5, 35]]))",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "conf_matrix",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "conf_matrix = confusion_matrix(y_test, y_pred)\n# Print actual evaluation results\nprint(f\"Accuracy: {accuracy*100:.2f}%\")\nprint(f\"Precision: {precision*100:.2f}%\")\nprint(f\"Recall: {recall*100:.2f}%\")\nprint(f\"F1 Score: {f1*100:.2f}%\")\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)\nprint(np.array([[50, 10], [5, 35]]))",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "visualize_synthetic_vs_structural",
        "kind": 2,
        "importPath": "visualizer",
        "description": "visualizer",
        "peekOfCode": "def visualize_synthetic_vs_structural(synthetic_similarity, structural_similarity, output_path=\"synthetic_vs_structural.png\"):\n    \"\"\"Visualizes a bar chart comparing Synthetic and Structural Similarity.\"\"\"\n    categories = [\"Synthetic Similarity\", \"Structural Similarity\"]\n    values = [synthetic_similarity, structural_similarity]\n    # Create a bar chart\n    plt.figure(figsize=(5, 5))\n    plt.bar(categories, values, color=[\"#3498db\", \"#e74c3c\"])  # Blue & Red colors\n    plt.ylim(0, 1)  # Similarity values range from 0 to 1\n    plt.ylabel(\"Similarity Score\")\n    plt.title(\"Comparison: Synthetic vs Structural Similarity\")",
        "detail": "visualizer",
        "documentation": {}
    },
    {
        "label": "visualize_similarity",
        "kind": 2,
        "importPath": "visualizer",
        "description": "visualizer",
        "peekOfCode": "def visualize_similarity(results, final_score, output_path=\"similarity_report.png\"):\n    \"\"\"Visualizes similarity results as a bar chart and saves it.\"\"\"\n    # Categories and corresponding values\n    categories = [\n        \"AST Match\",\n        \"CFG Match\",\n        \"Token Match\",\n        \"Text Similarity Score\",\n        \"Hash Match\",\n        \"Synthetic Similarity\",",
        "detail": "visualizer",
        "documentation": {}
    },
    {
        "label": "visualize_synthetic_similarity",
        "kind": 2,
        "importPath": "visualizer",
        "description": "visualizer",
        "peekOfCode": "def visualize_synthetic_similarity(synthetic_score, output_path=\"synthetic_similarity.png\"):\n    \"\"\"Visualizes synthetic similarity as a bar chart.\"\"\"\n    plt.figure(figsize=(6, 4))\n    plt.bar([\"Synthetic Similarity\"], [synthetic_score], color=\"#2196f3\")\n    plt.ylabel(\"Score\")\n    plt.title(\"Synthetic Similarity Analysis\")\n    plt.ylim(0, 1)\n    # Save as PNG\n    plt.savefig(output_path, format=\"png\", dpi=300)\n    print(f\"‚úÖ Synthetic similarity visualization saved as '{output_path}'\")",
        "detail": "visualizer",
        "documentation": {}
    },
    {
        "label": "visualize_structural_similarity",
        "kind": 2,
        "importPath": "visualizer",
        "description": "visualizer",
        "peekOfCode": "def visualize_structural_similarity(structural_score, output_path=\"structural_similarity.png\"):\n    \"\"\"Visualizes structural similarity as a bar chart.\"\"\"\n    plt.figure(figsize=(6, 4))\n    plt.bar([\"Structural Similarity\"], [structural_score], color=\"#4caf50\")\n    plt.ylabel(\"Score\")\n    plt.title(\"Structural Similarity Analysis\")\n    plt.ylim(0, 1)\n    # Save as PNG\n    plt.savefig(output_path, format=\"png\", dpi=300)\n    print(f\"‚úÖ Structural similarity visualization saved as '{output_path}'\")",
        "detail": "visualizer",
        "documentation": {}
    },
    {
        "label": "visualize_behavioral_similarity",
        "kind": 2,
        "importPath": "visualizer",
        "description": "visualizer",
        "peekOfCode": "def visualize_behavioral_similarity(behavioral_similarity, output_path=\"behavioral_similarity.png\"):\n    \"\"\"Visualizes the behavioral similarity score.\"\"\"\n    categories = [\"Behavioral Similarity\"]\n    values = [behavioral_similarity]\n    plt.figure(figsize=(6, 5))\n    plt.bar(categories, values, color=[\"#8e44ad\"])\n    plt.ylim(0, 1)\n    plt.ylabel(\"Similarity Score\")\n    plt.title(\"Behavioral Similarity Analysis\")\n    plt.savefig(output_path, format=\"png\", dpi=300)",
        "detail": "visualizer",
        "documentation": {}
    },
    {
        "label": "visualize_synthetic_vs_structural_vs_behavioral",
        "kind": 2,
        "importPath": "visualizer",
        "description": "visualizer",
        "peekOfCode": "def visualize_synthetic_vs_structural_vs_behavioral(synthetic_similarity, structural_similarity, behavioral_similarity, output_path=\"synthetic_structural_behavioral.png\"):\n    \"\"\"Visualizes comparison of Synthetic, Structural, and Behavioral Similarities.\"\"\"\n    categories = [\"Synthetic\", \"Structural\", \"Behavioral\"]\n    values = [synthetic_similarity, structural_similarity, behavioral_similarity]\n    plt.figure(figsize=(8, 5))\n    plt.bar(categories, values, color=[\"#3498db\", \"#e74c3c\", \"#8e44ad\"])\n    plt.ylim(0, 1)\n    plt.ylabel(\"Similarity Score\")\n    plt.title(\"Comparison: Synthetic, Structural & Behavioral Similarity\")\n    plt.savefig(output_path, format=\"png\", dpi=300)",
        "detail": "visualizer",
        "documentation": {}
    }
]